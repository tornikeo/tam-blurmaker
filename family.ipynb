{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Woo hoo. Let's go!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from cli import *\n",
    "\n",
    "print(\"Woo hoo. Let's go!\")\n",
    "\n",
    "# args, defined in track_anything.py\n",
    "# args = parse_argument()\n",
    "# args = default_args()\n",
    "args = argparse.Namespace()\n",
    "args.input = Path(\"test_sample/family_480.mp4\")\n",
    "args.track_data = Path(\"test_sample/family_480/sample_track_person.json\")\n",
    "args.device = \"cpu\"\n",
    "args.sam_model_type = \"vit_b\"\n",
    "args.output = Path(\"output.json\")\n",
    "args.debug = False\n",
    "args.mask_save = False\n",
    "args.output_video = Path(\"result.mp4\")\n",
    "args.track_data = json.load(open(args.track_data, \"r\"))\n",
    "# return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': {'frame': 200},\n",
       " 'points': [{'frame': 200, 'pos': [180, 176], 'label': 1}],\n",
       " 'end': {'frame': 300}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BaseSegmenter to cpu\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check and download checkpoints if needed\n",
    "SAM_checkpoint_dict = {\n",
    "    \"vit_h\": \"sam_vit_h_4b8939.pth\",\n",
    "    \"vit_l\": \"sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"sam_vit_b_01ec64.pth\",\n",
    "}\n",
    "SAM_checkpoint_url_dict = {\n",
    "    \"vit_h\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "    \"vit_l\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n",
    "}\n",
    "sam_checkpoint = SAM_checkpoint_dict[args.sam_model_type]\n",
    "sam_checkpoint_url = SAM_checkpoint_url_dict[args.sam_model_type]\n",
    "xmem_checkpoint = \"XMem-s012.pth\"\n",
    "xmem_checkpoint_url = (\n",
    "    \"https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem-s012.pth\"\n",
    ")\n",
    "e2fgvi_checkpoint = \"E2FGVI-HQ-CVPR22.pth\"\n",
    "e2fgvi_checkpoint_id = \"10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3\"\n",
    "\n",
    "folder = \"./checkpoints\"\n",
    "SAM_checkpoint = download_checkpoint(sam_checkpoint_url, folder, sam_checkpoint)\n",
    "xmem_checkpoint = download_checkpoint(xmem_checkpoint_url, folder, xmem_checkpoint)\n",
    "e2fgvi_checkpoint = download_checkpoint_from_google_drive(\n",
    "    e2fgvi_checkpoint_id, folder, e2fgvi_checkpoint\n",
    ")\n",
    "# args.port = 12212\n",
    "# args.device = \"cuda:1\"\n",
    "# args.mask_save = True\n",
    "\n",
    "# initialize sam, xmem, e2fgvi models\n",
    "model = TrackingAnything(SAM_checkpoint, xmem_checkpoint, None, args)\n",
    "# video_input: /tmp/182f5d11c044d7004053ecf4b9f0678894a151ab/mall_480.mp4\n",
    "# video_state: {'user_name': '', 'video_name': '', 'origin_images': None, 'painted_images': None, 'masks': None, 'inpaint_masks': None, 'logits': None, 'select_frame_number': 0, 'fps': 30}\n",
    "interactive_state = {\n",
    "    \"inference_times\": 0,\n",
    "    \"negative_click_times\": 0,\n",
    "    \"positive_click_times\": 0,\n",
    "    \"mask_save\": args.mask_save,\n",
    "    \"multi_mask\": {\"mask_names\": [], \"masks\": []},\n",
    "    \"track_end_number\": args.track_data[\"end\"]['frame'],\n",
    "    \"resize_ratio\": 1,\n",
    "}\n",
    "video_state = {\n",
    "    \"track_start_number\": args.track_data[\"start\"]['frame'],\n",
    "    \"user_name\": \"\",\n",
    "    \"video_name\": \"\",\n",
    "    \"origin_images\": None,\n",
    "    \"painted_images\": None,\n",
    "    \"masks\": None,\n",
    "    \"inpaint_masks\": None,\n",
    "    \"logits\": None,\n",
    "    \"select_frame_number\": 0,\n",
    "    \"fps\": 30,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state, video_info, origin_image = get_frames_from_video(\n",
    "    model,\n",
    "    args.input,\n",
    "    video_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "points = args.track_data['points']\n",
    "\n",
    "template_frame, video_state, interactive_state, run_status=select_template(\n",
    "    model,\n",
    "    points[0]['frame'], \n",
    "    video_state, \n",
    "    interactive_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evt = argparse.Namespace()\n",
    "evt.index = [0, 0]\n",
    "template_frame, video_state, interactive_state, run_status = sam_refine(\n",
    "    model=model,\n",
    "    video_state=video_state,\n",
    "    # point_prompt=sam_refine_args['point_prompt'],\n",
    "    point_prompt=None,#\"Positive\",\n",
    "    click_state=None,#[[180,176],[1]],\n",
    "    prompt={\n",
    "        \"prompt_type\": [\"click\"],\n",
    "        \"input_point\": [points[0]['pos']],#[[180,176]],\n",
    "        \"input_label\": [points[0]['label']],\n",
    "        \"multimask_output\": \"False\",\n",
    "    },\n",
    "    interactive_state=interactive_state,\n",
    "    evt=evt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'output_video'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m video_output, video_state, interactive_state, run_status \u001b[39m=\u001b[39m vos_tracking_video(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m----> 3\u001b[0m     video_output\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39;49moutput_video,\n\u001b[1;32m      4\u001b[0m     video_state\u001b[39m=\u001b[39mvideo_state,\n\u001b[1;32m      5\u001b[0m     interactive_state\u001b[39m=\u001b[39minteractive_state,\n\u001b[1;32m      6\u001b[0m     mask_dropdown\u001b[39m=\u001b[39m[],\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m outputs \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'output_video'"
     ]
    }
   ],
   "source": [
    "\n",
    "video_output, video_state, interactive_state, run_status = vos_tracking_video(\n",
    "    model=model,\n",
    "    video_output=args.output_video,\n",
    "    video_state=video_state,\n",
    "    interactive_state=interactive_state,\n",
    "    mask_dropdown=[],\n",
    ")\n",
    "outputs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bbox2(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    try:\n",
    "        rmin, rmax = np.where(rows)[0][[0, -1]].tolist()\n",
    "        cmin, cmax = np.where(cols)[0][[0, -1]].tolist()\n",
    "        return rmin, rmax, cmin, cmax\n",
    "    except IndexError:\n",
    "        return None\n",
    "# video_state[\"masks\"][video_state[\"select_frame_number\"]] = mask\n",
    "for frame_num, mask in enumerate(video_state[\"masks\"]):\n",
    "    # print(mask)\n",
    "    # print(i)\n",
    "    # mask = np.load(mask)\n",
    "    # Get bounding box [x,y,x,y] from binary mask\n",
    "    bbox = bbox2(mask > 0)\n",
    "    if bbox is not None:\n",
    "        # Write outputs in {1: {'class': 0, 'bbox': [0, 0, 0, 0], 'score': ''}} format\n",
    "        outputs.append({frame_num: {'class': 0, 'bbox': bbox, 'score': ''}})\n",
    "\n",
    "# Write outputs to json\n",
    "Path(args.output).open('w').write(json.dumps({\n",
    "    'results': outputs\n",
    "}, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
